{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d1fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/static/images/icons/wikipedia.png\n",
      "/static/images/mobile/copyright/wikipedia-wordmark-en.svg\n",
      "/static/images/mobile/copyright/wikipedia-tagline-en.svg\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/1/1b/Semi-protection-shackle.svg/20px-Semi-protection-shackle.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/20px-Sound-icon.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Cheese_platter.jpg/260px-Cheese_platter.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Clara_Peeters_-_Still_Life_with_Cheeses%2C_Almonds_and_Pretzels.jpg/260px-Clara_Peeters_-_Still_Life_with_Cheeses%2C_Almonds_and_Pretzels.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Hartkaese_HardCheeses.jpg/220px-Hartkaese_HardCheeses.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Ricotta_affumicata_della_sila.jpg/220px-Ricotta_affumicata_della_sila.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Formaggi.JPG/220px-Formaggi.JPG\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/3/38/9-alimenti%2C_formaggi%2CTaccuino_Sanitatis%2C_Casanatense_4182..jpg/220px-9-alimenti%2C_formaggi%2CTaccuino_Sanitatis%2C_Casanatense_4182..jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/3/32/Cheese_display%2C_Cambridge_MA_-_DSC05391.jpg/220px-Cheese_display%2C_Cambridge_MA_-_DSC05391.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Flag_of_Europe.svg/23px-Flag_of_Europe.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/23px-Flag_of_the_United_States.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/b/ba/Flag_of_Germany.svg/23px-Flag_of_Germany.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/c/c3/Flag_of_France.svg/23px-Flag_of_France.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/0/03/Flag_of_Italy.svg/23px-Flag_of_Italy.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/2/20/Flag_of_the_Netherlands.svg/23px-Flag_of_the_Netherlands.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/1/12/Flag_of_Poland.svg/23px-Flag_of_Poland.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Flag_of_Canada_%28Pantone%29.svg/23px-Flag_of_Canada_%28Pantone%29.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Flag_of_Egypt.svg/23px-Flag_of_Egypt.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/f/f3/Flag_of_Russia.svg/23px-Flag_of_Russia.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/8/82/Production_of_cheese_1.jpg/220px-Production_of_cheese_1.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Cheeseinthenetherlands.JPG/220px-Cheeseinthenetherlands.JPG\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/53/Parmigiano_reggiano_factory.jpg/220px-Parmigiano_reggiano_factory.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Wikicheese_-_Brie_de_Melun_-_20150515_-_015.jpg/323px-Wikicheese_-_Brie_de_Melun_-_20150515_-_015.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Bleu_de_Gex.jpg/240px-Bleu_de_Gex.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/9/96/Maccagno_%28cheese%29.jpg/247px-Maccagno_%28cheese%29.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/40/Berkswell_cheese.jpg/270px-Berkswell_cheese.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/6/66/Maroilles_%28cheese%29.jpg/180px-Maroilles_%28cheese%29.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/50/Mozzarella_cheese.jpg/240px-Mozzarella_cheese.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/44/Queso_fresco.JPG/240px-Queso_fresco.JPG\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/42/Smoked_Gruy%C3%A8re_cheese.jpg/240px-Smoked_Gruy%C3%A8re_cheese.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/7/71/Bergader_Almk%C3%A4se_Chili_01_WikiCheese_Lokal_K.jpg/257px-Bergader_Almk%C3%A4se_Chili_01_WikiCheese_Lokal_K.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/00928_Beskider_K%C3%A4se_aus_Schafsmilch_2013%3B_Sheep%27s-milk_cheeses_from_Poland%3B_Northern_Subcarpathians.JPG/272px-00928_Beskider_K%C3%A4se_aus_Schafsmilch_2013%3B_Sheep%27s-milk_cheeses_from_Poland%3B_Northern_Subcarpathians.JPG\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/C%C5%93urs_de_Neufch%C3%A2tel_01.jpg/320px-C%C5%93urs_de_Neufch%C3%A2tel_01.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Cowgirl_Creamery_Point_Reyes_-_Devil%E2%80%99s_Gulch_cheese.jpg/270px-Cowgirl_Creamery_Point_Reyes_-_Devil%E2%80%99s_Gulch_cheese.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Camembert_%28Cheese%29.jpg/240px-Camembert_%28Cheese%29.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/6/68/WikiCheese_-_Saint-Julien_aux_noix_01.jpg/270px-WikiCheese_-_Saint-Julien_aux_noix_01.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/7/76/Bavaria_blu_03_WikiCheese_Lokal_K.jpg/277px-Bavaria_blu_03_WikiCheese_Lokal_K.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/52/SmallEdamCheese.jpg/240px-SmallEdamCheese.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/5d/Sainte-Maure_de_touraine_03.jpg/270px-Sainte-Maure_de_touraine_03.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/56/WikiCheese_-_Tentation_du_Vercors_-_20150619_-_001.jpg/320px-WikiCheese_-_Tentation_du_Vercors_-_20150619_-_001.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Bleu_d%27%C3%89lizabeth.jpg/180px-Bleu_d%27%C3%89lizabeth.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/6/6e/M%C3%A9t%C3%A9orite_fromage.jpg/270px-M%C3%A9t%C3%A9orite_fromage.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/40/Ricotta_salata_e_zucchina.jpg/270px-Ricotta_salata_e_zucchina.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/c/c0/WikiCheese_-_Rigotte_de_Condrieu_-_20150619_-_001.jpg/320px-WikiCheese_-_Rigotte_de_Condrieu_-_20150619_-_001.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Parmigiano_Reggiano_DOP_Billa.jpg/270px-Parmigiano_Reggiano_DOP_Billa.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Chabichou_du_Poitou_01.jpg/320px-Chabichou_du_Poitou_01.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/8/86/Gr%C3%BCnschimmelk%C3%A4se_%C3%96sterkron.jpg/270px-Gr%C3%BCnschimmelk%C3%A4se_%C3%96sterkron.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/7/79/Reblochon_01.jpg/320px-Reblochon_01.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/5/53/Pouligny-saint-pierre_%28fromage%29_02.jpg/320px-Pouligny-saint-pierre_%28fromage%29_02.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/6/62/Fourme_d%27Ambert_01.jpg/320px-Fourme_d%27Ambert_01.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Blue_Stilton_02.jpg/320px-Blue_Stilton_02.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/46/Langres_fromage_AOP_coupe.jpg/225px-Langres_fromage_AOP_coupe.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Emmental_%28fromage%29_01.jpg/320px-Emmental_%28fromage%29_01.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/8/81/2014-12-08_Bergk%C3%A4se_mit_Antipasta_5713.jpg/292px-2014-12-08_Bergk%C3%A4se_mit_Antipasta_5713.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/8/86/2015-01-25_Tobermory%2C_Isle_of_Mull_Cheese_Sgriob-ruadh_Farm_-_hu_-_7900.jpg/227px-2015-01-25_Tobermory%2C_Isle_of_Mull_Cheese_Sgriob-ruadh_Farm_-_hu_-_7900.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Zacharie_Cloutier_%28fromage%29.jpg/270px-Zacharie_Cloutier_%28fromage%29.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/0/03/Sauermilchkaese_diverse.jpg/332px-Sauermilchkaese_diverse.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Cowgirl_Creamery_Point_Reyes_-_Red_Hawk_cheese.jpg/250px-Cowgirl_Creamery_Point_Reyes_-_Red_Hawk_cheese.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Gruyere_alpage_th_wa.jpg/178px-Gruyere_alpage_th_wa.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Wikicheese_-_Brie_de_Nangis_-_20150515_-_018.jpg/270px-Wikicheese_-_Brie_de_Nangis_-_20150515_-_018.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/48/Rouelle_du_Tarn.jpg/240px-Rouelle_du_Tarn.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Comte_AOP.jpg/284px-Comte_AOP.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Cheese%2C_wine_and_bread_in_a_sidewalk_cafe_in_Paris%2C_June_2015.jpg/220px-Cheese%2C_wine_and_bread_in_a_sidewalk_cafe_in_Paris%2C_June_2015.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Cormeilles_Market_9_Artlibre_jnl.jpg/220px-Cormeilles_Market_9_Artlibre_jnl.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Oscypek_sheeps_cheese_stalls%2C_Zakopane.JPG/220px-Oscypek_sheeps_cheese_stalls%2C_Zakopane.JPG\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/45px-Sound-icon.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Foodlogo2.svg/32px-Foodlogo2.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/40px-Wikibooks-logo-en-noslogan.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/14px-Commons-logo.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/16px-Wikiquote-logo.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikibooks-logo.svg/19px-Wikibooks-logo.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Wikivoyage-Logo-v3-icon.svg/19px-Wikivoyage-Logo-v3-icon.svg.png\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/2/28/Milk_001.JPG/63px-Milk_001.JPG\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/0/00/Different_ketchup_in_a_plate_122425.jpg/128px-Different_ketchup_in_a_plate_122425.jpg\n",
      "//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png\n",
      "//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\n",
      "/static/images/footer/wikimedia-button.png\n",
      "/static/images/footer/poweredby_mediawiki_88x31.png\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "    \n",
    "def getdata(url): \n",
    "    r = requests.get(url) \n",
    "    return r.text \n",
    "    \n",
    "htmldata = getdata(\"https://en.wikipedia.org/wiki/Cheese\") \n",
    "soup = BeautifulSoup(htmldata, 'html.parser') \n",
    "for item in soup.find_all('img'):\n",
    "    print(item['src'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed490214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: urllib3 in ./Library/Python/3.9/lib/python/site-packages (2.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# only for first time, may not be necessary\n",
    "# pip install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4a5305",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib3' has no attribute 'urlopen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlsplit\n\u001b[1;32m      6\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://filmygyan.in/katrina-kaifs-top-10-cutest-pics-gallery/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m urlContent \u001b[38;5;241m=\u001b[39m \u001b[43murllib3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m(url)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# HTML image tag: <img src=\"url\" alt=\"some_text\"/>\u001b[39;00m\n\u001b[1;32m      9\u001b[0m imgUrls \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg .*?src=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, urlContent)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'urllib3' has no attribute 'urlopen'"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import re\n",
    "from os.path import basename\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "url = \"http://filmygyan.in/katrina-kaifs-top-10-cutest-pics-gallery/\"\n",
    "urlContent = urllib3.urlopen(url).read()\n",
    "# HTML image tag: <img src=\"url\" alt=\"some_text\"/>\n",
    "imgUrls = re.findall('img .*?src=\"(.*?)\"', urlContent)\n",
    "\n",
    "# download all images\n",
    "for imgUrl in imgUrls:\n",
    "    try:\n",
    "        imgData = urllib3.urlopen(imgUrl).read()\n",
    "        fileName = basename(urlsplit(imgUrl)[2])\n",
    "        output = open(fileName,'wb')\n",
    "        output.write(imgData)\n",
    "        output.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247ce418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter URL:- https://en.wikipedia.org/wiki/Cheese\n",
      "Enter Folder Name:- /Users/dslc/Documents/Github/Algorithmic-Bias/Web-Scraping/Images\n",
      "Total 84 Image Found!\n",
      "Total 0 Images Downloaded Out of 84\n"
     ]
    }
   ],
   "source": [
    "from bs4 import *\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "def folder_create(images):\n",
    "    try:\n",
    "        folder_name = input(\"Enter Folder Name:- \")\n",
    "        # folder creation\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "    \n",
    "    except:\n",
    "        print(\"Folder Exist with that name!\")\n",
    "        folder_create()\n",
    "\n",
    "    \n",
    "    download_images(images, folder_name)\n",
    "\n",
    "\n",
    "def download_images(images, folder_name):\n",
    "    count = 0\n",
    "    print(f\"Total {len(images)} Image Found!\")\n",
    "    if len(images) != 0:\n",
    "        for i, image in enumerate(images):          \n",
    "            try:    \n",
    "                image_link = image[\"data-srcset\"]\n",
    "            except:\n",
    "                try:\n",
    "                    \n",
    "                    image_link = image[\"data-src\"]\n",
    "                except:\n",
    "                    try:\n",
    "                        \n",
    "                        image_link = image[\"data-fallback-src\"]\n",
    "                    except:\n",
    "                        try:\n",
    "                            \n",
    "                            image_link = image[\"src\"]\n",
    "\n",
    "                        \n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                r = requests.get(image_link).content\n",
    "                try:\n",
    "\n",
    "                    # possibility of decode\n",
    "                    r = str(r, 'utf-8')\n",
    "\n",
    "                except UnicodeDecodeError:\n",
    "\n",
    "                    with open(f\"{folder_name}/images{i+1}.jpg\", \"wb+\") as f:\n",
    "                        f.write(r)\n",
    "                    count += 1\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "        if count == len(images):\n",
    "            print(\"All Images Downloaded!\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Total {count} Images Downloaded Out of {len(images)}\")\n",
    "\n",
    "def main(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    images = soup.findAll('img')\n",
    "    folder_create(images)\n",
    "\n",
    "url = input(\"Enter URL:- \")\n",
    "main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f929673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dslc'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95429b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter URL:- https://en.wikipedia.org/wiki/Cheese\n",
      "Enter Folder Name:- /Users/dslc/Documents/Github/Algorithmic-Bias/Web-Scraping/Images2\n",
      "Total 84 Image Found!\n",
      "Total 0 Images Downloaded Out of 84\n"
     ]
    }
   ],
   "source": [
    "from bs4 import *\n",
    "import requests\n",
    "import os\n",
    " \n",
    "# CREATE FOLDER\n",
    "def folder_create(images):\n",
    "    try:\n",
    "        folder_name = input(\"Enter Folder Name:- \")\n",
    "        # folder creation\n",
    "        os.mkdir(folder_name)\n",
    " \n",
    "    # if folder exists with that name, ask another name\n",
    "    except:\n",
    "        print(\"Folder Exist with that name!\")\n",
    "        folder_create()\n",
    " \n",
    "    # image downloading start\n",
    "    download_images(images, folder_name)\n",
    " \n",
    " \n",
    "# DOWNLOAD ALL IMAGES FROM THAT URL\n",
    "def download_images(images, folder_name):\n",
    "   \n",
    "    # initial count is zero\n",
    "    count = 0\n",
    " \n",
    "    # print total images found in URL\n",
    "    print(f\"Total {len(images)} Image Found!\")\n",
    " \n",
    "    # checking if images is not zero\n",
    "    if len(images) != 0:\n",
    "        for i, image in enumerate(images):\n",
    "            # From image tag ,Fetch image Source URL\n",
    " \n",
    "                        # 1.data-srcset\n",
    "                        # 2.data-src\n",
    "                        # 3.data-fallback-src\n",
    "                        # 4.src\n",
    " \n",
    "            # Here we will use exception handling\n",
    " \n",
    "            # first we will search for \"data-srcset\" in img tag\n",
    "            try:\n",
    "                # In image tag ,searching for \"data-srcset\"\n",
    "                image_link = image[\"data-srcset\"]\n",
    "                 \n",
    "            # then we will search for \"data-src\" in img\n",
    "            # tag and so on..\n",
    "            except:\n",
    "                try:\n",
    "                    # In image tag ,searching for \"data-src\"\n",
    "                    image_link = image[\"data-src\"]\n",
    "                except:\n",
    "                    try:\n",
    "                        # In image tag ,searching for \"data-fallback-src\"\n",
    "                        image_link = image[\"data-fallback-src\"]\n",
    "                    except:\n",
    "                        try:\n",
    "                            # In image tag ,searching for \"src\"\n",
    "                            image_link = image[\"src\"]\n",
    " \n",
    "                        # if no Source URL found\n",
    "                        except:\n",
    "                            pass\n",
    " #REQUESTSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS\n",
    "            # After getting Image Source URL\n",
    "            # We will try to get the content of image\n",
    "            try:\n",
    "                r = requests.get(image_link).content\n",
    "                try:\n",
    " \n",
    "                    # possibility of decode\n",
    "                    r = str(r, 'utf-8')\n",
    " \n",
    "                except UnicodeDecodeError:\n",
    " \n",
    "                    # After checking above condition, Image Download start\n",
    "                    with open(f\"{folder_name}/images{i+1}.jpg\", \"wb+\") as f:\n",
    "                        f.write(r)\n",
    " \n",
    "                    # counting number of image downloaded\n",
    "                    count += 1\n",
    "            except:\n",
    "                pass\n",
    " \n",
    "        # There might be possible, that all\n",
    "        # images not download\n",
    "        # if all images download\n",
    "        if count == len(images):\n",
    "            print(\"All Images Downloaded!\")\n",
    "             \n",
    "        # if all images not download\n",
    "        else:\n",
    "            print(f\"Total {count} Images Downloaded Out of {len(images)}\")\n",
    " \n",
    "# MAIN FUNCTION START\n",
    "def main(url):\n",
    "   \n",
    "    # content of URL\n",
    "    r = requests.get(url)\n",
    " \n",
    "    # Parse HTML Code\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    " \n",
    "    # find all images in URL\n",
    "    images = soup.findAll('img')\n",
    " \n",
    "    # Call folder create function\n",
    "    folder_create(images)\n",
    " \n",
    " \n",
    "# take url\n",
    "url = input(\"Enter URL:- \")\n",
    " \n",
    "# CALL MAIN FUNCTION\n",
    "main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572a179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sucessfully Downloaded:  summer-4823612_960_720.jpg\n"
     ]
    }
   ],
   "source": [
    "## Importing Necessary Modules\n",
    "import requests # to get image from the web\n",
    "import shutil # to save it locally\n",
    "\n",
    "## Set up the image URL and filename\n",
    "image_url = \"https://cdn.pixabay.com/photo/2020/02/06/09/39/summer-4823612_960_720.jpg\"\n",
    "filename = image_url.split(\"/\")[-1]\n",
    "\n",
    "# Open the url image, set stream to True, this will return the stream content.\n",
    "r = requests.get(image_url, stream = True)\n",
    "\n",
    "# Check if the image was retrieved successfully\n",
    "if r.status_code == 200:\n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    r.raw.decode_content = True\n",
    "    \n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    with open(filename,'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "        \n",
    "    print('Image sucessfully Downloaded: ',filename)\n",
    "else:\n",
    "    print('Image Couldn\\'t be retreived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cf05574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "that\n"
     ]
    }
   ],
   "source": [
    "urls = ['this', 'that']\n",
    "for x in urls:\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcd55eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sucessfully Downloaded:  summer-4823612_960_720.jpg\n",
      "Image sucessfully Downloaded:  pexels-photo-2893685.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500\n",
      "Image sucessfully Downloaded:  photo-1554080353-a576cf803bda?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8NHx8cGhvdG98ZW58MHx8MHx8fDA%3D&w=1000&q=80\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "urls = ['https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Cheese_platter.jpg/520px-Cheese_platter.jpg'\n",
    "for x in urls:\n",
    "    filename = x.split(\"/\")[-1]\n",
    "\n",
    "# Open the url image, set stream to True, this will return the stream content.\n",
    "    r = requests.get(x, stream = True)\n",
    "\n",
    "# Check if the image was retrieved successfully\n",
    "    if r.status_code == 200:\n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        r.raw.decode_content = True\n",
    "    \n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "        with open(filename,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "        print('Image sucessfully Downloaded: ',filename)\n",
    "    else:\n",
    "        print('Image Couldn\\'t be retreived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3ece4e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'that': No scheme supplied. Perhaps you meant https://that?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     filename \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Open the url image, set stream to True, this will return the stream content.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check if the image was retrieved successfully\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Set decode_content value to True, otherwise the downloaded image file's size will be zero.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    483\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    485\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 486\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'that': No scheme supplied. Perhaps you meant https://that?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "urls = ['https://cdn.pixabay.com/photo/2020/02/06/09/39/summer-4823612_960_720.jpg']\n",
    "for x in urls:\n",
    "    filename = x.split(\"/\")[-1]\n",
    "\n",
    "# Open the url image, set stream to True, this will return the stream content.\n",
    "r = requests.get(image_url, stream = True)\n",
    "\n",
    "# Check if the image was retrieved successfully\n",
    "if r.status_code == 200:\n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    r.raw.decode_content = True\n",
    "    \n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    with open(filename,'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "        \n",
    "    print('Image sucessfully Downloaded: ',filename)\n",
    "else:\n",
    "    print('Image Couldn\\'t be retreived')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
